{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0f91de2",
   "metadata": {},
   "source": [
    "Foundation API Information\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b28802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize libraries\n",
    "import requests\n",
    "from requests import api\n",
    "from requests.models import Response\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "import json\n",
    "import bcrypt\n",
    "from datetime import datetime, timezone\n",
    "from pprint import pprint\n",
    "from tabulate import tabulate\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "base_url = os.getenv('BASE_URL')\n",
    "api_key = os.getenv('API_KEY')\n",
    "api_key_value = os.getenv('API_KEY_VALUE')\n",
    "impersonate = os.getenv('IMPERSONATE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c34e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get_foundation_headers - Use bcrypt to hash the API key with a timestamp per Litera documentation\n",
    "def get_foundation_headers():\n",
    "    instant_timestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")[:-1] + \"0Z\"  \n",
    "    combined = api_key_value + \"|\" + instant_timestamp\n",
    "    salt = bcrypt.gensalt()\n",
    "    hashed = bcrypt.hashpw(combined.encode('utf-8'), salt)\n",
    "    hashed_key = hashed, instant_timestamp\n",
    "    result = {'x-foundation-api-key': api_key, 'x-foundation-timestamp': hashed_key[1], 'x-foundation-api-auth': hashed_key[0], \"x-foundation-impersonate\": impersonate, \"accept\":\"application/json\"}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c1b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get metadata from the Foundation Metadata API endpoint and return it as JSON\n",
    "def get_foundation_metadata():\n",
    "    headers = get_foundation_headers()\n",
    "    url = f\"{base_url}api/v1/application/metadata\"\n",
    "    response = requests.get(url, headers=headers) #, verify=False\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        metadata = response.json()\n",
    "        return metadata\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Download the metadata as a Python dictionary\n",
    "data = json.loads(json.dumps(get_foundation_metadata(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af6625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matter Custom Field CSV exported to \\\\docs-oc\\files\\KMOBAPPS\\Foundation\\MetaData\\foundation_matter_custom_fields_api.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## Create and export a table of Matter fields with associated configurations\n",
    "# Construct a table listing matter custom fields with their IDs and descriptions\n",
    "MCFtable = []\n",
    "# for field in data['matterCustomFieldTypes']:\n",
    "#     sourceRecordID = field.get('sourceRecordId', '')\n",
    "#     field_name = field.get('name', '')\n",
    "#     field_datatype = field.get('dataType', '')\n",
    "#     field_description = field.get('description', '')\n",
    "#     MCFtable.append([sourceRecordID, field_datatype, '', field_name, field_description])\n",
    "\n",
    "# Append the matter fields to the table\n",
    "for field in data['matterFields']:\n",
    "    field_ID = field.get('name', '')\n",
    "    field_name = field.get('displayName', '')\n",
    "    # Check for a match between field_ID and the \"id\" key in matterObjectTypes\n",
    "    matched_object = next((obj for obj in data.get('matterObjectTypes', []) if obj.get('id') == field_ID), None)\n",
    "    if matched_object:\n",
    "        field_ID = matched_object.get('sourceRecordId', field_ID)\n",
    "    # Check for a match between field_ID and the \"id\" key in matterCustomFieldTypes\n",
    "    matched_object = next((obj for obj in data.get('matterCustomFieldTypes', []) if obj.get('id') == field_ID), None)\n",
    "    if matched_object:\n",
    "        field_ID = matched_object.get('sourceRecordId', field_ID)\n",
    "    field_datatype = field.get('dataTypeName', '')\n",
    "    field_type = field.get('fieldType', '')\n",
    "    field_description = field.get('description', '')\n",
    "    # Only append if the field_name is not already present in MCFtable (from matterCustomFieldTypes)\n",
    "    if field_name not in [row[1] for row in MCFtable]:\n",
    "        MCFtable.append([field_ID, field_datatype, field_type, field_name, field_description])\n",
    "\n",
    "# Sort the table by sourceRecordID (first column) in ascending order\n",
    "MCFtable_sorted = sorted(MCFtable, key=lambda x: x[0])\n",
    "#print(tabulate(MCFtable_sorted, headers=[\"Field ID\", \"Field Data Type\", \"Field Type\", \"Field Name\", \"Description\"], tablefmt=\"github\"))\n",
    "\n",
    "# Export the sorted table to a CSV file\n",
    "csv_path = r'\\\\docs-oc\\files\\KMOBAPPS\\Foundation\\MetaData\\foundation_matter_custom_fields_api.csv'\n",
    "with open(csv_path, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Field ID\", \"Field Data Type\", \"Field Type\", \"Field Name\", \"Description\"])\n",
    "    writer.writerows(MCFtable_sorted)\n",
    "print(f\"Matter Custom Field CSV exported to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and export a table of Person fields with associated configurations\n",
    "\n",
    "# Construct a table listing people custom fields with their IDs and descriptions\n",
    "PCFtable = []\n",
    "for field in data['personCustomFieldTypes']:\n",
    "    sourceRecordID = field.get('sourceRecordId', '')\n",
    "    field_name = field.get('name', '')\n",
    "    field_description = field.get('description', '')\n",
    "    PCFtable.append([sourceRecordID, field_name, field_description])\n",
    "\n",
    "# Append the pre-defined person fields to the table\n",
    "for field in data['personFields']:\n",
    "    field_ID = field.get('name', '')\n",
    "    field_name = field.get('displayName', '')\n",
    "    field_description = field.get('description', '')\n",
    "    # Only append if the field_name is not already present in PCFtable (from personCustomFieldTypes)\n",
    "    if field_name not in [row[1] for row in PCFtable]:\n",
    "        PCFtable.append([field_ID, field_name, field_description])\n",
    "\n",
    "# Sort the table by sourceRecordID (first column) in ascending order\n",
    "PCFtable_sorted = sorted(PCFtable, key=lambda x: x[0])\n",
    "print(tabulate(PCFtable_sorted, headers=[\"Field ID\", \"Field Name\", \"Description\"], tablefmt=\"github\"))\n",
    "\n",
    "# Export the sorted table to a CSV file\n",
    "# \\\\docs-oc\\files\\KMOBAPPS\\Foundation\\MetaData\n",
    "csv_path = r'\\\\docs-oc\\files\\KMOBAPPS\\Foundation\\MetaData\\foundation_person_custom_fields_api.csv'\n",
    "with open(csv_path, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Field ID\", \"Field Name\", \"Description\"])\n",
    "    writer.writerows(PCFtable_sorted)\n",
    "print(f\"Person Custom Field CSV exported to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a1e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "## search_all_attys - Query the Search API endpoint for firm attorneys\n",
    "def search_all_attys():\n",
    "    headers = get_foundation_headers()\n",
    "    url = f\"{base_url}search/search\"\n",
    "    #office = input(\"Enter the office location to search for: \")\n",
    "    params = {\n",
    "        \"q\": f\"Person((OR(personProfileType~Attorneys)))\",\n",
    "    #    \"facetBehavior\": \"0\",\n",
    "    #    \"specificFacets\": \"string\",\n",
    "    #    \"sort\": \"string\",\n",
    "        \"take\": \"1000\",\n",
    "        \"skip\": \"0\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    print({response.status_code})\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        all_atty_data = response.json()\n",
    "        #pprint(metadata)\n",
    "        return all_atty_data\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "    \n",
    "#search_response = search_people_by_office()\n",
    "\n",
    "# Download the metadata as a Python dictionary\n",
    "people_data = json.loads(json.dumps(search_all_attys(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51b59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## search_all_people_by_office - Query the Search API endpoint for firm people by office\n",
    "def search_all_people_by_office():\n",
    "    headers = get_foundation_headers()\n",
    "    url = f\"{base_url}search/search\"\n",
    "    office = input(\"Enter the office location to search for: \")\n",
    "    params = {\n",
    "        \"q\": f\"Person((OR(primaryOffice~{office})))\",\n",
    "    #    \"facetBehavior\": \"0\",\n",
    "    #    \"specificFacets\": \"string\",\n",
    "    #    \"sort\": \"string\",\n",
    "        \"take\": \"500\",\n",
    "        \"skip\": \"0\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    print({response.status_code})\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        people_by_office_data = response.json()\n",
    "        #pprint(metadata)\n",
    "        return people_by_office_data\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "    \n",
    "#search_response = search_people_by_office()\n",
    "\n",
    "# Download the metadata as a Python dictionary\n",
    "people_data = json.loads(json.dumps(search_all_people_by_office(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find and display all attorneys\n",
    "\n",
    "# Initialize a list to hold the people data by office\n",
    "people_by_office_table = []\n",
    "\n",
    "#Construct a table that lists lawyer data for the selected office\n",
    "for person in people_data['items']:\n",
    "    person_ID = person.get('id', '')\n",
    "    person_firstname = person.get('first', '')\n",
    "    person_lastname = person.get('last', '')\n",
    "    person_title = person.get('title', '')\n",
    "    person_office = person.get('primaryOffice', '')\n",
    "    person_website = person.get('urlWebSite', '')\n",
    "    if person_website is None:\n",
    "        people_by_office_table.append([person_ID, person_firstname, person_lastname, person_title, person_office, person_website])\n",
    "\n",
    "# Sort the table by sourceRecordID (first column) in ascending order\n",
    "people_by_office_table_sorted = sorted(people_by_office_table, key=lambda x: x[2]) #Sort by last name\n",
    "print(f\"Number of people in table: {len(people_by_office_table_sorted)}\")\n",
    "print(tabulate(people_by_office_table_sorted, headers=[\"Person ID\", \"First Name\", \"Last Name\", \"Title\", \"Office\", \"Website\"], tablefmt=\"github\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafe8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## search_all_pitches_rfps - Query the Search API endpoint for pitch/RFP packets\n",
    "\n",
    "# Query the Search API endpoint for pitches and RFPs\n",
    "def search_all_pitches_rfps():\n",
    "    headers = get_foundation_headers()\n",
    "    url = f\"{base_url}search/search\"\n",
    "    params = {\n",
    "    #    \"q\": f\"Packet()\",\n",
    "    #    \"q\": f\"Packet((OR(packetTypeId~870d5871-dbc7-42c1-ae26-f5825d62fef8~Pitch/RFP)))\",\n",
    "        \"q\": f\"Packet((OR(packetTypeId~870d5871-dbc7-42c1-ae26-f5825d62fef8~Pitch/RFP)) (OR(tagCategory-ab5a0c6f-b9d0-401e-8f6d-d8e843ce52ba-DAYRANGE~365)))\",\n",
    "    #    \"facetBehavior\": \"0\",\n",
    "    #    \"specificFacets\": \"string\",\n",
    "    #    \"sort\": \"string\",\n",
    "        \"take\": \"500\",\n",
    "        \"skip\": \"0\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    print({response.status_code})\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        all_pitch_rfp_data = response.json()\n",
    "        pprint(all_pitch_rfp_data)\n",
    "        return all_pitch_rfp_data\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "    \n",
    "# Download the metadata as a Python dictionary\n",
    "pitch_rfp_data = json.loads(json.dumps(search_all_pitches_rfps(), indent=4))\n",
    "#pprint(pitch_rfp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find and display all pitch/RFP packets\n",
    "\n",
    "# Initialize a list to hold the people data by office\n",
    "pitch_rfp_table = []\n",
    "\n",
    "#Construct a table that lists lawyer data for the selected office\n",
    "for packet in pitch_rfp_data['items']:\n",
    "    packet_ID = packet.get('id', '')\n",
    "    packet_name = packet.get('name', '')\n",
    "    custom_fields = packet.get('customFieldsDisplay', {})\n",
    "    # Get the specific field value\n",
    "    packet_pitch_status = custom_fields.get('7cfd3225-2a70-4e21-9c56-55924b44c7c9', '')\n",
    "    packet_pitch_content_matt = custom_fields.get('195bbaea-9463-48fa-8cff-c86f15e1fc2d', '')\n",
    "    packet_target_type = custom_fields.get('bbbcc750-ddb9-4e50-b422-e384d63a60bd', '')\n",
    "    packet_gen_prac_scope = custom_fields.get('a5040ad6-e8d0-4a10-bbcb-9588e701ce70', '')\n",
    "    packet_case_cite = custom_fields.get('45eb3006-061b-4db0-9946-6e5040b5d4bd', '')\n",
    "    packet_kmob_industry = custom_fields.get('83be4625-df49-4dee-98de-07b68256d9a2', '')\n",
    "    #packet_title = packet.get('title', '')\n",
    "    #packet_office = packet.get('primaryOffice', '')\n",
    "    #packet_website = packet.get('urlWebSite', '')\n",
    "    pitch_rfp_table.append([packet_ID, packet_name, packet_pitch_status, packet_pitch_content_matt, packet_target_type, packet_gen_prac_scope, packet_case_cite, packet_kmob_industry])\n",
    "\n",
    "# Sort the table by sourceRecordID (first column) in ascending order\n",
    "pitch_rfp_table_sorted = sorted(pitch_rfp_table, key=lambda x: x[1]) #Sort by packet name\n",
    "print(f\"Number of packets in table: {len(pitch_rfp_table_sorted)}\")\n",
    "print(tabulate(pitch_rfp_table_sorted, headers=[\"Packet ID\", \"Packet Name\", \"Pitch/RFP Status\", \"Pitch Content Matter\", \"Target Type\", \"General Practice Scope\", \"Case Citation\", \"Knobbe Industry\"], tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1878d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
